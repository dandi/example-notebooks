{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "The purpose of this Jupyter Notebook is to illustrate key processes in our software pipeline that utlilizes NWB. Our hope is that this notebook can serve as a tutorial on reading and extracting data from an NWB file. Here, we demonstrate how to run single neuron analysis in NWB. We probed for the tuning of two functional cell types, MS and VS cells, Memory Selective, and  Visually Seletive, respectively.\n",
    "\n",
    "This notebook has been adapted from: \n",
    "\n",
    "> Chandravadia, N., Liang, D., Schjetnan, A. G. P., Carlson, A., Faraut, M., Chung, J. M., Reed, C. M., Dichter, B., Maoz, U., Kalia, S. K., Valiante, T. A., Mamelak, A. N. & Rutishauser, U. A NWB-based dataset and processing pipeline of human single-neuron activity during a declarative memory task. Scientific Data 7, 78, (2020). [Link to paper](https://www.nature.com/articles/s41597-020-0415-9)\n",
    "\n",
    "to work directly on the DANDI dataset. The repository for this analysis can be found [here](https://github.com/rutishauserlab/recogmem-release-NWB), and the original version of this notebook can be found [here](https://github.com/rutishauserlab/recogmem-release-NWB/blob/master/RutishauserLabtoNWB/events/newolddelay/python/analysis/demo/demoAnalysis.ipynb).\n",
    "\n",
    "* Author: [Nand Chandravadia](nandc10@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install RutishauserLabtoNWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pynwb import NWBHDF5IO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dandi.download import download as dandi_download\n",
    "import RutishauserLabtoNWB.events.newolddelay.python.analysis.helper as helper\n",
    "import RutishauserLabtoNWB.events.newolddelay.python.analysis.single_neuron as single_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Path to the NWB file here:\n",
    "\n",
    "url = \"https://api.dandiarchive.org/api/assets/757c3982-8e4c-466d-9a9f-73793262268c/download/\"\n",
    "dandi_download([url], os.getcwd(), existing=\"skip\")\n",
    "\n",
    "\n",
    "pathtoNWBFile = 'sub-P9HMH_ses-20060301_obj-1otd1m8_ecephys+image.nwb'\n",
    "nwbBasePath = Path(pathtoNWBFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the nwb file \n",
    "io = NWBHDF5IO(str(nwbBasePath), mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "#Get the fields within the NWB file\n",
    "nwbFields = nwb.fields\n",
    "print('These are the top-level Groups within the NWB file: {}\\n'.format(nwbFields.keys()))\n",
    "\n",
    "#Get Meta-Data from NWB file \n",
    "print('The experiment within this NWB file was conducted at {} in the lab of {}. The experiment is detailed as follows: {}'.format(nwb.institution, nwb.lab, nwb.experiment_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data and Meta-data\n",
    "Here, we read the data and meta-data from the specified NWB file using the NWB read utility. \n",
    "\n",
    "The NWB file is composed of various Groups, Datasets, and Attributes. The data and corresponding meta-data are encapsulated within these Groups. The data are thus organized according to these Groups. We can also read the data and meta-data within these Groups, and visualize the components within NWB file via the *nwb2widget* utility -- the following illustrates this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot the Waveforms from the NWB file\n",
    "\n",
    "#Which channel_index to plot? \n",
    "channel_index = [0]\n",
    "\n",
    "# get Waveform Means from the NWB file\n",
    "allwaveformLearn = np.asarray(nwb.units['waveform_mean_encoding'].data)\n",
    "allwaveformRecog = np.asarray(nwb.units['waveform_mean_recognition'].data)\n",
    "\n",
    "# Choose Which Channel Index to Plot\n",
    "waveformLearn = allwaveformLearn[channel_index, :][0]\n",
    "waveformRecog = allwaveformLearn[channel_index, :][0]\n",
    "\n",
    "#get brain Areas\n",
    "brainAreas = np.asarray(nwb.electrodes['location'].data)\n",
    "\n",
    "\n",
    "#Plot the mean waveforms\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (15, 10)) \n",
    "\n",
    "#Plot Learning\n",
    "axes[0].plot(range(len(waveformLearn)), waveformLearn, color = 'blue', marker = 'o', linestyle='dashed',\n",
    "            linewidth=1, markersize=3)\n",
    "axes[0].set_title('Learning, session: {}, brain Area: {}'.format(nwb.identifier, brainAreas[channel_index][0]))\n",
    "axes[0].set_xlabel('time (in ms)')\n",
    "axes[0].set_ylabel('\\u03BCV')\n",
    "\n",
    "\n",
    "#Plot Recog\n",
    "axes[1].plot(range(len(waveformRecog)), waveformRecog, color = 'green', marker = 'o', linestyle='dashed',\n",
    "            linewidth=1, markersize=3)\n",
    "axes[1].set_title('Recognition, session: {}, brain Area: {}'.format(nwb.identifier, brainAreas[channel_index][0]))\n",
    "axes[1].set_xlabel('time (in ms)')\n",
    "axes[1].set_ylabel('\\u03BCV')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Plotting the Mean Waveform(s)\n",
    "\n",
    "To extract the mean waveform, we simply call waveform_mean_encoding from the \\units table -- *nwb.units['waveform_mean_encoding']*. The brain area of each of the electrodes is located within the \\electrodes table -- *nwb.electrodes['location']*. To see the relationship between the \\units and \\electrodes table, see **Figure 2b** in our data descriptor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Behavior from NWB file \n",
    "\n",
    "# == Plot ROC curve == \n",
    "fig, axes = plt.subplots(1, 3, figsize = (25, 10))\n",
    "# Calculate the cumulative d and plot the cumulative ROC curve\n",
    "stats_all = helper.cal_cumulative_d(nwb)\n",
    "# Calculate the auc\n",
    "auc = helper.cal_auc(stats_all)\n",
    "x = stats_all[0:5, 4]\n",
    "y = stats_all[0:5, 3]\n",
    "axes[2].plot(x, y, marker='.', color='grey', alpha=0.5, linewidth=2, markersize=3)\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].set_xlim(0, 1)\n",
    "axes[2].set_title('ROC Curve, AUC: {}'.format(auc))\n",
    "axes[2].set_xlabel('False Positive Rate')\n",
    "axes[2].set_ylabel('True Positive Rate')\n",
    "axes[2].plot([0, 1], [0, 1], color='black', alpha=0.5, linewidth=2)\n",
    "\n",
    "\n",
    "#Get the recognition responses\n",
    "recog_response = helper.extract_recog_responses(nwb)\n",
    "ground_truth = helper.extract_new_old_label(nwb)\n",
    "#Get the recognition responses for the 'old' stimuli\n",
    "recog_response_old = recog_response[ground_truth == 1]\n",
    "\n",
    "# Place holder ready to store separate the new and old response\n",
    "response_1_old = []\n",
    "response_2_old = []\n",
    "response_3_old = []\n",
    "response_4_old = []\n",
    "response_5_old = []\n",
    "response_6_old = []\n",
    "\n",
    "response_1_new = []\n",
    "response_2_new = []\n",
    "response_3_new = []\n",
    "response_4_new = []\n",
    "response_5_new = []\n",
    "response_6_new = []\n",
    "\n",
    "\n",
    "# Calculate the percentage of each responses\n",
    "response_1_old.append(np.sum(recog_response_old == 1) / len(recog_response_old))\n",
    "response_2_old.append(np.sum(recog_response_old == 2) / len(recog_response_old))\n",
    "response_3_old.append(np.sum(recog_response_old == 3) / len(recog_response_old))\n",
    "response_4_old.append(np.sum(recog_response_old == 4) / len(recog_response_old))\n",
    "response_5_old.append(np.sum(recog_response_old == 5) / len(recog_response_old))\n",
    "response_6_old.append(np.sum(recog_response_old == 6) / len(recog_response_old))\n",
    "\n",
    "recog_response_new = recog_response[ground_truth == 0]\n",
    "response_1_new.append(np.sum(recog_response_new == 1) / len(recog_response_new))\n",
    "response_2_new.append(np.sum(recog_response_new == 2) / len(recog_response_new))\n",
    "response_3_new.append(np.sum(recog_response_new == 3) / len(recog_response_new))\n",
    "response_4_new.append(np.sum(recog_response_new == 4) / len(recog_response_new))\n",
    "response_5_new.append(np.sum(recog_response_new == 5) / len(recog_response_new))\n",
    "response_6_new.append(np.sum(recog_response_new == 6) / len(recog_response_new))\n",
    "\n",
    "\n",
    "# Plot the percentage responses\n",
    "response_old = np.asarray([response_1_old, response_2_old, response_3_old, response_4_old,\n",
    "                               response_5_old, response_6_old])\n",
    "response_new = np.asarray([response_1_new, response_2_new, response_3_new, response_4_new,\n",
    "                               response_5_new, response_6_new])\n",
    "\n",
    "n = 1\n",
    "response_percentage_old = np.mean(response_old, axis=1)\n",
    "std_old = np.std(response_old)\n",
    "se_old = std_old/np.sqrt(n)\n",
    "response_percentage_new = np.mean(response_new, axis=1)\n",
    "std_new = np.std(response_new)\n",
    "se_new = std_new/np.sqrt(n)\n",
    "\n",
    "#x = [i for i in range(1, 7, 1)]\n",
    "x = ['New, very sure', 'New, sure', 'New, unsure', 'Old, unsure', 'Old, sure', 'Old, very sure']\n",
    "axes[1].errorbar(x, response_percentage_old, yerr=se_old, color='blue', label='old stimuli', linewidth = 2)\n",
    "axes[1].errorbar(x, response_percentage_new, yerr=se_new, color='red', label='new stimuli', linewidth = 2)\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Confidence')\n",
    "axes[1].set_ylabel('Probability of Response')\n",
    "\n",
    "\n",
    "\n",
    "# == Plot the Response Times for correct vs. incorrect responses == \n",
    "\n",
    "events_learn, timestamps_learn, events_recog, timestamps_recog = helper.get_event_data(nwb)\n",
    "\n",
    "data_events = {'events_recog': events_recog, 'timestamps_recog': timestamps_recog}\n",
    "recog = pd.DataFrame(data_events) \n",
    "\n",
    "index_questionScreenOnset = list(np.where(recog['events_recog'] == 3)) #question screen onset\n",
    "\n",
    "response_recog = helper.extract_recog_responses(nwb)\n",
    "ground_truth = helper.extract_new_old_label(nwb)\n",
    "correct_ind, incorrect_ind = helper.correct_incorrect_indexes(recog_response, ground_truth)\n",
    "\n",
    "responseTimesRecogCorrect = []\n",
    "responseTimesRecogIncorrect = []\n",
    "\n",
    "#Get response times for correct trials, from question screen onset\n",
    "for a in index_questionScreenOnset[0][correct_ind]: \n",
    "    responseTime = recog.iloc[a+1, 1] - recog.iloc[a, 1]\n",
    "    responseTimesRecogCorrect.append(responseTime)\n",
    "    \n",
    "#Get response times for incorrect trials, from question screen onset\n",
    "for a in index_questionScreenOnset[0][incorrect_ind]: \n",
    "    responseTime = recog.iloc[a+1, 1] - recog.iloc[a, 1]\n",
    "    responseTimesRecogIncorrect.append(responseTime)\n",
    "\n",
    "accuracy = len(correct_ind)/len(response_recog)\n",
    "\n",
    "\n",
    "responseTimesAll = responseTimesRecogCorrect + responseTimesRecogIncorrect\n",
    "trial_indication = ['Correct']*len(responseTimesRecogCorrect) + ['Incorrect']*len(responseTimesRecogIncorrect)\n",
    "dict_responseTimes = {'time': responseTimesAll, 'trial': trial_indication}\n",
    "dataframe_responseTimes = pd.DataFrame(dict_responseTimes)\n",
    "\n",
    "#Plot Boxplot\n",
    "sns.boxplot(x = 'trial', y= \"time\", data = dataframe_responseTimes, ax = axes[0], color = 'b')\n",
    "sns.swarmplot(x = 'trial', y= \"time\", data=dataframe_responseTimes, color=\"g\", ax = axes[0])\n",
    "axes[0].set_ylabel('time (measured in s)')\n",
    "axes[0].set_title('Response times for all trials, accuracy: {}'.format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior\n",
    "\n",
    "We can plot the behavior from the NWB file. The behavioral data is mostly encapsulated within nwb\\trials, which includes the trial information such as the start_time and response_time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot the Neuron(s)\n",
    "\n",
    "#Get the spike times from the NWB file \n",
    "index = 0\n",
    "nwb.units.get_unit_spike_times(index)\n",
    "\n",
    "neurons = single_neuron.extract_neuron_data_from_nwb(nwb)\n",
    "\n",
    "#Plot all the Neurons\n",
    "for neuron in neurons:\n",
    "    neuron.raster_psth(cell_type='visual', bin_size = 150)\n",
    "    neuron.raster_psth(cell_type = 'memory', bin_size = 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
